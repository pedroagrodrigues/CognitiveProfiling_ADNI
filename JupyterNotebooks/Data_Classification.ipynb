{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c097154c-00d0-4679-82fa-e5a6882b4ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Training = 0.3 # Using 30% of the data to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d437bca9-cfec-46ba-b6d1-9a0d9d7057e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Graphs\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib widget\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import common\n",
    "\n",
    "# The way Pandas is being used in this file is deprecated. It will eventually stop working. The next lines hide all warnings:\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Loading Datasets\n",
    "data = common.loadFile(\"CleanedData\").drop([\"RID\", \"VISCODE\", \"PTEDUCAT\", \"PTGENDER\", \"AGE\"], axis=1)\n",
    "reconstructedData = common.loadFile(\"filledData\").drop([\"PTEDUCAT\", \"PTGENDER\", \"AGE\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea78ba83-7f1b-4006-a937-ed8c9efd9c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [DecisionTreeClassifier, KNeighborsClassifier, LinearDiscriminantAnalysis, GaussianNB, SVC, LinearSVC, RandomForestClassifier]\n",
    "labels = [\"Decision Tree\", \"K-Nearest Neighbors\", \"Linear Discriminant Analysis\", \"Guassian Naïve Bayes\", \"Support Vector Classification\", \"Linear SVC\", \"Random Forest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2784c0e5-f764-45b4-becc-e5ce069b8cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing testing for every model\n",
    "def getModelScore(model, xTrain, xTest, yTrain, yTest):\n",
    "    model.fit(xTrain, yTrain)\n",
    "    return model.score(xTest, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2c776fa-b8d3-47c7-adcb-74197949c441",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = normalize(data.drop(\"DX\", axis=1).to_numpy().astype('float'))\n",
    "RX = normalize(reconstructedData.drop([\"DX\"], axis=1).to_numpy().astype('float'))\n",
    "\n",
    "y = data.loc[:,['DX']].to_numpy().astype('float').flatten()\n",
    "Ry = reconstructedData.loc[:,['DX']].to_numpy().astype('float').flatten()\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=Training)\n",
    "Rxtrain, Rxtest, Rytrain, Rytest = train_test_split(RX, Ry, test_size=Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02370f22-4c56-4e37-ab77-288c826c61b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleScore = [getModelScore(i(), xtrain, xtest, ytrain, ytest) * 100 for i in algorithms]\n",
    "crossValidationScore = [cross_val_score(i(), X, y, cv=10) for i in algorithms]\n",
    "RSimpleScore = [getModelScore(i(), Rxtrain, Rxtest, Rytrain, Rytest) * 100 for i in algorithms]\n",
    "RCrossValidationScore = [cross_val_score(i(), RX, Ry, cv=10) for i in algorithms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34fd56c1-60a4-4409-9ff4-de3bd71a03d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0c9a709f89a401abeaa0e7fdd59eb9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[18, 10])\n",
    "\n",
    "df = pd.DataFrame(columns = ['Algorithm', 'Method', 'Score'])\n",
    "\n",
    "for i, n in zip(labels, range(len(labels))):\n",
    "    df = df.append({\"Algorithm\" : i, \"Method\" : \"Simple Validation\", \"Score\": round(simpleScore[n], 2)}, ignore_index=True)\n",
    "    df = df.append({\"Algorithm\" : i, \"Method\" : \"Cross Validation\", \"Score\": round(sum(crossValidationScore[n])/len(crossValidationScore[n]) *100, 2)}, ignore_index=True)\n",
    "    \n",
    "ax = sns.barplot(x=\"Algorithm\", y=\"Score\", hue=\"Method\", data=df)\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt=\"%.2f%%\")\n",
    "\n",
    "ax.set(xlabel='Algorithms', ylabel='Scores (%)', title=f\"Clean Data Score with {int(Training * 100)}% of Training\")\n",
    "plt.tight_layout(pad=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caacec15-b3c3-4264-8b49-efdd3f0491c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15dfbe61cc3942f9baa6c810fef61669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[18, 10])\n",
    "\n",
    "df = pd.DataFrame(columns = ['Algorithm', 'Method', 'Score'])\n",
    "\n",
    "for i, n in zip(labels, range(len(labels))):\n",
    "    df = df.append({\"Algorithm\" : i, \"Method\" : \"Simple Validation\", \"Score\": round(RSimpleScore[n], 2)}, ignore_index=True)\n",
    "    df = df.append({\"Algorithm\" : i, \"Method\" : \"Cross Validation\", \"Score\": round(sum(RCrossValidationScore[n])/len(RCrossValidationScore[n]) *100, 2)}, ignore_index=True)\n",
    "    \n",
    "ax = sns.barplot(x=\"Algorithm\", y=\"Score\", hue=\"Method\", data=df)\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt=\"%.2f%%\")\n",
    "\n",
    "ax.set(xlabel='Algorithms', ylabel='Scores (%)', title=f\"Filled Data Score with {int(Training * 100)}% of Training\")\n",
    "plt.tight_layout(pad=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4ae160-5ecf-4b7a-b676-715647c6411b",
   "metadata": {},
   "source": [
    "Validating clean data with reconstructed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef76e3be-2a97-4e65-b129-c4494d8c4484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data is from the complete dataset.\n",
    "mixedXtrain = normalize(data.drop(\"DX\", axis=1).to_numpy().astype('float'))\n",
    "mixedYtrain = data.loc[:,['DX']].to_numpy().astype('float').flatten()\n",
    "\n",
    "# Testing will be done with the recustructed data\n",
    "mixedXtest = normalize(reconstructedData.drop([\"DX\",'numFilledLabels'], axis=1).to_numpy().astype('float'))\n",
    "mixedYtest = reconstructedData.loc[:,['DX']].to_numpy().astype('float').flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c01b949b-b503-48db-8642-825104e6b4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixedSimpleScore = [getModelScore(i(), mixedXtrain, mixedXtest, mixedYtrain, mixedYtest) * 100 for i in algorithms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38662dfb-67e6-4280-9e3d-b5017ce41f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9426bcc7f99c484e93fe0986347a3293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[18, 8])\n",
    "df = pd.DataFrame(columns = ['Algorithm', 'Method', 'Score'])\n",
    "\n",
    "for i, n in zip(labels, range(len(labels))):\n",
    "    df = df.append({\"Algorithm\" : i, \"Method\" : \"Reconstructed Validation\", \"Score\": round(mixedSimpleScore[n], 2)}, ignore_index=True)\n",
    "    df = df.append({\"Algorithm\" : i, \"Method\" : \"Complete Data Validation\", \"Score\": round(simpleScore[n], 2)}, ignore_index=True)\n",
    "    df = df.append({\"Algorithm\" : i, \"Method\" : \"Complete Data Cross Validation\", \"Score\": round(sum(crossValidationScore[n])/len(crossValidationScore[n]) *100, 2)}, ignore_index=True)\n",
    "    #df = df.append({\"Algorithm\" : i, \"Method\" : \"Cross Validation\", \"Score\": round(sum(crossValidationScore[n])/len(crossValidationScore[n]) *100, 2)}, ignore_index=True)\n",
    "\n",
    "\n",
    "ax = sns.barplot(x=\"Algorithm\", y=\"Score\", hue=\"Method\", data=df, edgecolor='white', linewidth=1)\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt=\"%.2f%%\", size=9)\n",
    "    \n",
    "ax.legend(loc='upper left', fontsize=9, bbox_to_anchor=(0, 1.1))\n",
    "\n",
    "ax.set(xlabel='Algorithms', ylabel='Scores (%)', title=f\"Clean Data Score with {int(Training * 100)}% of Training\", ylim=(0,100))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(10))\n",
    "plt.tight_layout(pad=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e828433-2d53-421a-9522-9e928426a810",
   "metadata": {},
   "outputs": [],
   "source": [
    "performanceData = reconstructedData.sort_values(by='numFilledLabels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e941632-aabd-452c-b51e-8ccd2e63b431",
   "metadata": {},
   "outputs": [],
   "source": [
    "performanceResults = {}\n",
    "for i in range(int(performanceData['numFilledLabels'].max()) + 1):\n",
    "    testingSet = performanceData.loc[performanceData.numFilledLabels == i]\n",
    "    if len(testingSet) == 0: \n",
    "        continue\n",
    "    else:\n",
    "        testingX = normalize(testingSet.drop([\"DX\", \"numFilledLabels\"], axis=1).to_numpy().astype(\"float\"))\n",
    "        testingY = testingSet.loc[:, [\"DX\"]].to_numpy().astype(\"float\").flatten()\n",
    "\n",
    "        # Notice: The training set was defined before the previous graph\n",
    "        newIteraction = [getModelScore(j(), mixedXtrain, testingX, mixedYtrain, testingY) * 100 for j in algorithms]\n",
    "        newIteraction.append(int(len(testingSet)))\n",
    "        performanceResults[i] = newIteraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01d6031a-9ddf-40c0-b71a-0967a27fedf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "performanceLabels = labels.copy()\n",
    "performanceLabels.insert(0, \"Index\")\n",
    "performanceLabels.append(\"Data Set Size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcb6f840-243b-422d-aa54-08d596134c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultDF = pd.DataFrame(columns=performanceLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bd1d557-0e91-4091-bec4-267c8592a58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in performanceResults:\n",
    "    if performanceResults[i] == np.nan: continue\n",
    "    row = [i]\n",
    "    for j in performanceResults[i]:\n",
    "        row.append(j)\n",
    "    \n",
    "    resultDF = resultDF.append(dict(zip(performanceLabels, row)), ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35357bea-7f29-491a-a5f3-6f79da4f37db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c62faf1538d4ced927761d5320f6013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[18, 8])\n",
    "ax = sns.scatterplot(x='Index', y='value', hue='variable', data=pd.melt(resultDF.drop(\"Data Set Size\", axis=1), ['Index']))\n",
    "ax.set(xlabel='Number of Missing Labels', ylabel='Scores (%)', title=\"Rebuild Performance\")\n",
    "plt.tight_layout(pad=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b5beab5-98e1-41e7-9ef9-8121f7fcac6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d276684330b243cf9951a89265f436c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[18, 8])\n",
    "ax = sns.barplot(x='Index', y='Data Set Size', data=resultDF)\n",
    "ax.set(xlabel='Number of Missing Labels', ylabel='Size of Dataset', title=\"Dataset Rebuild Size\")\n",
    "ax.xaxis.set_major_locator(ticker.MaxNLocator(integer=True) )\n",
    "plt.tight_layout(pad=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d84c1124-1601-470f-8ab3-f0479bdbbab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "incrementalPerformanceResults = {}\n",
    "for i in range(int(performanceData['numFilledLabels'].max()) + 1):\n",
    "    testingSet = performanceData.loc[performanceData.numFilledLabels >= i]\n",
    "    if len(testingSet) == 0: \n",
    "        continue\n",
    "    else:\n",
    "        testingX = normalize(testingSet.drop([\"DX\", \"numFilledLabels\"], axis=1).to_numpy().astype(\"float\"))\n",
    "        testingY = testingSet.loc[:, [\"DX\"]].to_numpy().astype(\"float\").flatten()\n",
    "\n",
    "        # Notice: The training set was defined before the previous graph\n",
    "        newIteraction = [getModelScore(j(), mixedXtrain, testingX, mixedYtrain, testingY) * 100 for j in algorithms]\n",
    "        newIteraction.append(int(len(testingSet)))\n",
    "        incrementalPerformanceResults[i] = newIteraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "611d5abf-5234-4ea8-a8a6-35779da00454",
   "metadata": {},
   "outputs": [],
   "source": [
    "incrementalResultDF = pd.DataFrame(columns=performanceLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f11c1c16-1f13-4899-8e54-368ffe1f96b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in incrementalPerformanceResults:\n",
    "    if incrementalPerformanceResults[i] == np.nan: continue\n",
    "    row = [i]\n",
    "    for j in incrementalPerformanceResults[i]:\n",
    "        row.append(j)\n",
    "    \n",
    "    incrementalResultDF = incrementalResultDF.append(dict(zip(performanceLabels, row)), ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82a78ed4-efc6-4270-9f53-756b49a471a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe432cd588f431e8bb77fd183446c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[18, 8])\n",
    "ax = sns.scatterplot(x='Index', y='value', hue='variable', data=pd.melt(incrementalResultDF.drop(\"Data Set Size\", axis=1), ['Index']))\n",
    "ax.set(xlabel='Number of Missing Labels (>n)', ylabel='Scores (%)', title=\"Incremental Rebuild Performance\")\n",
    "plt.tight_layout(pad=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1ebeaa2-72bc-46b2-96bb-65b6a573bb69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27725f1a281242f4a5cd992d5bcf454d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[18, 8])\n",
    "ax = sns.barplot(x='Index', y='Data Set Size', data=incrementalResultDF)\n",
    "ax.set(xlabel='Number of Missing Labels (>n)', ylabel='Size of Dataset', title=\"Dataset Incremental Rebuild Size\")\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container)\n",
    "    \n",
    "ax.xaxis.set_major_locator(ticker.MaxNLocator(integer=True) )\n",
    "    \n",
    "plt.tight_layout(pad=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3efadeea-7614-41e0-9885-c081139cb615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the labels\n",
    "dxLabels = ['CN', 'MCI', 'Dementia']\n",
    "\n",
    "# Create models\n",
    "models = [x().fit(mixedXtrain, mixedYtrain) for x in algorithms]\n",
    "    \n",
    "graphs = []\n",
    "\n",
    "for i in range(40):\n",
    "    testingSet = performanceData.loc[performanceData.numFilledLabels >= i]\n",
    "    currentTest = testingSet.drop([\"DX\", \"numFilledLabels\"], axis=1)\n",
    "    interaction = {}\n",
    "    for j in range(len(models)):\n",
    "        cm = confusion_matrix(testingSet.DX, models[j].predict(currentTest), labels=models[j].classes_)\n",
    "        df = pd.DataFrame(cm, dxLabels, dxLabels)\n",
    "        interaction[labels[j]] = df\n",
    "    interaction[\"size\"] = len(testingSet)\n",
    "    graphs.append(interaction)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "15c0ca87-2a24-4f76-9ab1-1065a4e73ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "625b6d3a-5664-4b93-a1f7-1b1c15538f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333c4cdee7d046f482c2426179e46ec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 25.722222222222214, 'Predicted Labels'),\n",
       " Text(70.72222222222221, 0.5, 'True Labels'),\n",
       " Text(0.5, 1.0, 'Linear Discriminant Analysis Algorithm for dataset >0 with size 5025')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 - \"Decision Tree\", 1 - \"K-Nearest Neighbors\", 2 - \"Linear Discriminant Analysis\", 3 - \"Guassian Naïve Bayes\", 4 - \"Support Vector Classification\", 5 - \"Linear SVC\", 6 - \"Random Forest\"\n",
    "index = 0 # Insert the number of missing values (0 to 39)\n",
    "algorithm = 2 # Insert the algorithm you whish to plot\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "ax = sns.heatmap(graphs[index][labels[algorithm]], annot=True, cmap=plt.cm.Blues, fmt='g')\n",
    "size = graphs[index][\"size\"]\n",
    "ax.set(xlabel='Predicted Labels', ylabel='True Labels', title=f\"{labels[algorithm]} Algorithm for dataset >{index} with size {size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f97dfd1-23f6-4c1c-b229-dd52984fea46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5025"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs[index][\"size\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
