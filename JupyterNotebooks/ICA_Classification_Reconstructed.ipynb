{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cfe4f77-e1bf-4774-9b64-7b5cfe2a7b58",
   "metadata": {},
   "source": [
    "# ICA Classification - Reconstructed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9cfce646-5e7d-40b4-9201-3d0e34d525f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Graphs\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "# Preprocessing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC, LinearSVC, SVR, LinearSVR\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import common\n",
    "\n",
    "\n",
    "# The way Pandas is being used in this file is deprecated. It will eventually stop working. The next lines hide all warnings:\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63add39a-ed7a-4243-a36c-0fa10d55460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = common.loadFile(\"CleanedData\").drop([\"VISCODE\", \"RID\"], axis=1).dropna()\n",
    "reconstructedData = common.loadFile(\"filledData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f48130fe-8116-480b-a1e7-32592820da44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d3fddf928be4bc9a695ade69f98490d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[5, 5])\n",
    "ax = sns.countplot(x=data['DX'])\n",
    "plt.title(\"Data Diagnosis\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Diagnosis\")\n",
    "plt.xticks(ticks=range(0,3), labels=['CN', 'MCI', 'Dementia'])\n",
    "\n",
    "for p in ax.patches:\n",
    "        ax.annotate(f'\\n{p.get_height()}', (p.get_x()+p.get_width()/2, p.get_height()), ha='center', \n",
    "                    va='top', color='white', size=18)\n",
    "plt.tight_layout(pad=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "718a5354-861d-4d9e-80da-b0d81aad7b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "DataX = data.drop(\"DX\", axis=1).to_numpy().astype('float')\n",
    "RDataX = reconstructedData.drop([\"DX\", \"numFilledLabels\"], axis=1).to_numpy().astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5073bfad-db04-45f7-897c-69841e565ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getComponentNames(components: np.ndarray) -> list:\n",
    "    res = []\n",
    "    for i in range(1, len(components.T)+1):\n",
    "        res.append('IC'+str(i))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fb1088d-c2fe-45d6-ac50-6a999ee1b77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "components = 10\n",
    "Training = 0.3\n",
    "\n",
    "# Creating ICA object\n",
    "ICA = FastICA(n_components=components, random_state=0) # Transform\n",
    "\n",
    "X_transformed = ICA.fit_transform(DataX)\n",
    "XR_transformed = ICA.transform(RDataX)\n",
    "\n",
    "Reduced_Data = pd.DataFrame(data=X_transformed, columns=getComponentNames(X_transformed))\n",
    "Reduced_Reconstructed_Data = pd.DataFrame(data=XR_transformed, columns=getComponentNames(XR_transformed))\n",
    "\n",
    "# Rebuild dataset\n",
    "ICA_Data = pd.concat([Reduced_Data, data[['DX']]], axis = 1)\n",
    "ICA_Data_Reconstructed = pd.concat([Reduced_Reconstructed_Data, reconstructedData[['DX']]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a11576c-42a0-4aa7-8981-e832d0d65774",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [DecisionTreeClassifier, KNeighborsClassifier, LinearDiscriminantAnalysis, GaussianNB, SVC, LinearSVC, RandomForestClassifier]\n",
    "labels = [\"Decision Tree\", \"K-Nearest Neighbors\", \"Linear Discriminant Analysis\", \"Guassian Naïve Bayes\", \"Support Vector Classification\", \"Linear SVC\", \"Random Forest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c666b79c-61ef-476a-b8f2-3f2f6fce452b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing testing for every model\n",
    "def getModelScore(model, xTrain, xTest, yTrain, yTest):\n",
    "    model.fit(xTrain, yTrain)\n",
    "    return model.score(xTest, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "387b70d5-dfb6-4160-8afb-0a045e3b3c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = normalize(ICA_Data.drop(\"DX\", axis=1).to_numpy().astype('float'))\n",
    "y = ICA_Data.loc[:,['DX']].to_numpy().astype('float').flatten()\n",
    "XR = normalize(ICA_Data_Reconstructed.drop(\"DX\", axis=1).to_numpy().astype('float'))\n",
    "yR = ICA_Data_Reconstructed.loc[:,['DX']].to_numpy().astype('float').flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b549925a-e90f-4af9-9bcd-faa53d9bf5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleScore = [getModelScore(i(), X, XR, y, yR) * 100 for i in algorithms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd289d52-3a23-447a-9e6c-6936f46eba05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b678bcd89ac24d1abf2a4d320828e71e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[18, 10])\n",
    "\n",
    "df = pd.DataFrame(columns = ['Algorithm', 'Method', 'Score'])\n",
    "\n",
    "for i, n in zip(labels, range(len(labels))):\n",
    "    df = df.append({\"Algorithm\" : i, \"Method\" : \"Simple Validation\", \"Score\": round(simpleScore[n], 2)}, ignore_index=True)\n",
    "    \n",
    "ax = sns.barplot(x=\"Algorithm\", y=\"Score\", data=df)\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt=\"%.2f%%\")\n",
    "\n",
    "ax.set(xlabel='Algorithms', ylabel='Scores (%)', title=f\"Reconstructed Data on ICA complete data\")\n",
    "plt.tight_layout(pad=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e25594c9-1979-4b32-bb51-fc7646386cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "performanceData = reconstructedData.sort_values(by='numFilledLabels')\n",
    "incrementalPerformanceResults = {}\n",
    "for i in range(int(performanceData['numFilledLabels'].max()) + 1):\n",
    "    testingSet = performanceData.loc[performanceData.numFilledLabels >= i]\n",
    "    if len(testingSet) == 0: \n",
    "        continue\n",
    "    else:\n",
    "        XR_transformed = ICA.transform(testingSet.drop([\"DX\", \"numFilledLabels\"], axis=1).to_numpy().astype(\"float\"))\n",
    "        \n",
    "        testingX = normalize(XR_transformed)\n",
    "        testingY = testingSet.loc[:, [\"DX\"]].to_numpy().astype(\"float\").flatten()\n",
    "\n",
    "        # Notice: The training set was defined before the previous graph\n",
    "        newIteraction = [getModelScore(j(), X, testingX, y, testingY) * 100 for j in algorithms]\n",
    "        newIteraction.append(int(len(testingSet)))\n",
    "        incrementalPerformanceResults[i] = newIteraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b3fbd48-9c12-4644-bbed-0f48610a23e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "performanceLabels = labels.copy()\n",
    "performanceLabels.insert(0, \"Index\")\n",
    "performanceLabels.append(\"Data Set Size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e54b2af-f91d-4b8c-9a64-ebced46e65cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "incrementalResultDF = pd.DataFrame(columns=performanceLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db83fe3d-eab2-449b-8712-a56c50a509ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in incrementalPerformanceResults:\n",
    "    if incrementalPerformanceResults[i] == np.nan: continue\n",
    "    row = [i]\n",
    "    for j in incrementalPerformanceResults[i]:\n",
    "        row.append(j)\n",
    "    \n",
    "    incrementalResultDF = incrementalResultDF.append(dict(zip(performanceLabels, row)), ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f49c561-cb8d-438a-85ce-fb74d1d45875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f840a3ef1504745979739b45a5e9b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[18, 8])\n",
    "ax = sns.scatterplot(x='Index', y='value', hue='variable', data=pd.melt(incrementalResultDF.drop(\"Data Set Size\", axis=1), ['Index']))\n",
    "ax.set(xlabel='Number of Missing Labels (>n)', ylabel='Scores (%)', title=\"Incremental Rebuild Performance using ICA\")\n",
    "plt.tight_layout(pad=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19de93d1-870d-4b9c-b00a-158b4474058a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23cb659a0d8c4ee4bdf5f2df0b8dd068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[18, 8])\n",
    "ax = sns.barplot(x='Index', y='Data Set Size', data=incrementalResultDF)\n",
    "ax.set(xlabel='Number of Missing Labels (>n)', ylabel='Size of Dataset', title=\"Dataset Incremental Rebuild Size\")\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container)\n",
    "    \n",
    "ax.xaxis.set_major_locator(ticker.MaxNLocator(integer=True) )\n",
    "    \n",
    "plt.tight_layout(pad=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bfddb12e-a00a-4c4f-aaf4-9ec3278c226e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the labels\n",
    "dxLabels = ['CN', 'MCI', 'Dementia']\n",
    "\n",
    "# Create models\n",
    "models = [x().fit(X, y) for x in algorithms]\n",
    "    \n",
    "graphs = []\n",
    "\n",
    "for i in range(40):\n",
    "    testingSet = performanceData.loc[performanceData.numFilledLabels >= i]\n",
    "    currentTest = testingSet.drop([\"DX\", \"numFilledLabels\"], axis=1)\n",
    "    \n",
    "    XR_transformed = ICA.transform(testingSet.drop([\"DX\", \"numFilledLabels\"], axis=1).to_numpy().astype(\"float\"))   \n",
    "    testingX = normalize(XR_transformed)\n",
    "    \n",
    "    interaction = {}\n",
    "    \n",
    "    for j in range(len(models)):\n",
    "        cm = confusion_matrix(testingSet.DX, models[j].predict(testingX), labels=models[j].classes_)\n",
    "        df = pd.DataFrame(cm, dxLabels, dxLabels)\n",
    "        interaction[labels[j]] = df\n",
    "    interaction[\"size\"] = len(testingSet)\n",
    "    graphs.append(interaction)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c5a8adc2-d7d4-42b0-b522-a262be722b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "53316276-3c69-4adb-9c83-d2ab1ac56449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad8861785c446a9875e0127b9384701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 25.722222222222214, 'Predicted Labels'),\n",
       " Text(70.72222222222221, 0.5, 'True Labels'),\n",
       " Text(0.5, 1.0, 'Linear Discriminant Analysis Algorithm for dataset >39 with size 204')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 - \"Decision Tree\", 1 - \"K-Nearest Neighbors\", 2 - \"Linear Discriminant Analysis\", 3 - \"Guassian Naïve Bayes\", 4 - \"Support Vector Classification\", 5 - \"Linear SVC\", 6 - \"Random Forest\"\n",
    "index = 39 # Insert the number of missing values (0 to 39)\n",
    "algorithm = 2 # Insert the algorithm you whish to plot\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "ax = sns.heatmap(graphs[index][labels[algorithm]], annot=True, cmap=plt.cm.Blues, fmt='g')\n",
    "size = graphs[index][\"size\"]\n",
    "ax.set(xlabel='Predicted Labels', ylabel='True Labels', title=f\"{labels[algorithm]} Algorithm for dataset >{index} with size {size}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
